# -*- coding: utf-8 -*-
"""Exploratory_Data_Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OGK1FiUUPIlgXXCWdWXnMamctHcMbRpA

# Descriptive Statistical
"""

import numpy as num
from sklearn.model_selection import train_test_split
x,y= num.arange(10).reshape((5,2)),range(5)

x

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.3,random_state=5)

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.33,random_state=12)

import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

x= np.array(x)
y = np.array(y)

df=pd.read_csv('/content/loan.2023.csv')
df.head()

df.describe()

"""# Visual Analysis"""

from matplotlib import pyplot as plt

x=[1,2,3]
y=[1,4,9]
z=[10,5,0]
plt.plot(x,y)
plt.plot(x,z)
plt.title("loan plot")
plt.xlabel("x")
plt.ylabel("y and z")
plt.legend(["this is y","this is z"])
plt.show()

sample_data=pd.read_csv('sample_data.csv')

sample_data

type(sample_data)

sample_data.column_c.iloc[0]

plt.plot(sample_data.column_a,sample_data.column_b,'o')
plt.plot(sample_data.column_a,sample_data.column_c)
plt.show()

data=pd.read_csv('loan.2023.csv')

data

pip install tensorflow==1.2.0 --ignore-installed

data[data.Married=='yes or no']

loan=data[data.Married=='yes or no']

"""# Univariate Analysis"""

plt.figure(figsize=(12,4))
plt.subplot(121)
sns.distplot(data['ApplicantIncome'],color='r')
plt.subplot(122)
sns.distplot(data['Credit_History'])
plt.show()

"""# Decision Tree Model"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,f1_

def DecisionTree(x_train, x_test, y_train, y_test):
  dt=DecisionTreeClassifier()
  dt.fit(x_train,y_train)
  yPred = dt.predict(x_test)
  print('***DecisionTreeClassifier***')
  print('confusion matrix')
  print(confusion_matrix(y_test,ypred))
  print('classification report')
  print(classification_report(y_test,ypred))

"""# Random Forest Model"""

def randomForest(x_train, x_test, y_train, y_test):
  rf = randomForestClassifier()
  rf.fit(x_train,y_train)
  ypred = rf.predict(x_test)
  print('***RandomForestClassifier***')
  print('confusion matrix')
  print(confusion_matrix(y_test,ypred))
  print('classification report')
  print(classification_report(y_test,ypred))

"""# KNN Model"""

def KNN(x_train, x_test, y_train, y_test):
  knn = KNeighborsClassifier()
  knn.fit(x_train,y_train)
  yPred = knn.predict(x_test)
  print('***KNeighborsClassifier***')
  print('confusion matrix')
  print(confusion_matrix(y_test,ypred))
  print('classification report')
  print(classification_report(y_test,ypred))

"""# Xgboost Model"""

def xgboost(x_train, x_test, y_train, y_test):
  xg = GradientboostClassifier()
  xg.fit(x_train,y_train)
  yPred = xg.predict(x_test)
  print('***GradientboostClassifier***')
  print('confusion matrix')
  print(confusion_matrix(y_test,ypred))
  print('classification report')
  print(classification_report(y_test,ypred))



"""# ANN Model"""

from tensorflow.python.keras.layers import Dense
Model.fit(train_dataset , validation_data=test_dataset)

# importing the keras libraies and packages
import tensorflow
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Initialising the ANN
classifier=Sequential()

# Adding the input layer and the first hidden layer
classifier.add(Dense(units=100,activation='relu',input_dim=11))

# Adding the second hidden layer
classifier.add(Dense(units=50,activation='relu'))

classifier.add(Dense(units=1,activation='sigmoid'))

from keras.api._v2.keras import metrics
# compailing the ANN
classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

# Fillin the ANN to thTraining set
model_history=classifier.fit(x_train,y_train,batch_size=100,validation_split=0.2,epochs=100)



